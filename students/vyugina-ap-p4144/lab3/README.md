# Отчет по лабораторной работе №3

## 1. Развертывание NVIDIA Triton Inference Server

Для развертывания NVIDIA Triton Inference Server необходимо выполнить следующие шаги:

1. Запуск Docker-контейнера с Triton Server (из текущей директории):
```bash
docker run --gpus=all -it --shm-size=256m --rm \
    -p9000:8000 -p9001:8001 -p9002:8002 \
    -v $(pwd)/triton-model-repository:/models \
    nvcr.io/nvidia/tritonserver:24.10-py3
```

2. Запуск Triton Server внутри контейнера:
```bash
tritonserver --model-repository=/models
```

Структура папки-хранилища моделей, которая монтируется в контейнер:
```
triton-model-repository/
└── yolov10s
    ├── 1
    │   └── model.onnx
    └── config.pbtxt
```

Содержимое файла-конфигурации для модели `YoloV10s`:
```
name: "yolov10s"
backend: "onnxruntime"
max_batch_size : 16
```

Все необходимые поля, такие как названия входов и выходов модели, будут найдены автоматически из файла модели. Для бэкенда ONNX их прописывать вручную нет необходимости.

## 2. Эндпоинты сервера

Сервер предоставляет следующие эндпоинты (порты изменены в настройках контейнера):
- `localhost:9000` - HTTP-сервер, `localhost:9000/v2/model/yolov10s/config` - просмотр текущей конфигурации модели (в том числе дополнительно сгенерированной)
- `localhost:9001` - GRPC-сервер
- `localhost:9002/metrics` - метрики сервера в формате Prometheus

## 3. Развернутый сервис
При помощи фреймворка Streamlit была развернута простейшая веб-страница для демонстрации работы контейнера. На веб-странице есть единственное поле для загрузки изображения. Посде загрузки отправляется запрос в сервис, результат выводится в виде изобрадения с разметкой и таблицей.

Запуск по команде: `streamlit run streamlit_demo.py`, выделенный порт и адрес будут указаны в выводе.

## 4. Результаты тестирования производительности

Было проведено тестирование производительности модели YOLOv10s в трех различных конфигурациях: `ONNX CPU`, `ONNX GPU`,`Nvidia Triton Server`. Результаты представлены в таблице (время обработки в миллисекундах на изображение):

| Batch Size | ONNX CPU (ms/img) | ONNX GPU (ms/img) | Triton (ms/img) |
|------------|-------------------|-------------------|-----------------|
| 1          | 688.123           | 109.372           | 141.249         |
| 2          | 858.990           | 81.299            | 131.055         |
| 3          | 663.755           | 79.889            | 141.393         |
| 4          | 717.707           | 71.758            | 108.876         |
| 5          | 652.893           | 68.009            | 94.017          |
| 6          | 652.248           | 66.085            | 92.839          |
| 7          | 724.533           | 66.994            | 95.649          |
| 8          | 625.818           | 65.917            | 95.586          |

### Анализ скорости
1. **ONNX CPU** показывает наихудшую производительность, с временем обработки от 625 до 858 мс на изображение. Сильно зависит от текущей нагрузки на процессор, особенно на ноутбуках.
2. **ONNX GPU** демонстрирует значительное ускорение по сравнению с CPU, с временем обработки от 65 до 109 мс на изображение.
3. **Triton Server** показывает производительность между CPU и GPU версиями, с временем обработки от 92 до 141 мс на изображение. 

### Стабильность
Также было выполнено сравнение результатов работы разных фреймворков: ONNX на CPU и Nvidia Triton. Если сохранять все детекции, в том числе и с низкой уверенностью, то выодные массивы могут совпадать неполностью. Это связано с внутренней работой сервисов, их оптимизациями и прочим. При этом, если провести постпроцессинг, то объекты, найденные с высокой уверенностью, полностью совпадут для обоих фреймворков.

## 5. Мониторинг
Nvidia Triton Server автоматически экспортирует метрики в формате Prometheus, поэтому для их мониторинга достаточно поднять в докер-контейнере Prometheus и Grafana для визуализации.

Для этого в папке `monitoring/` лежат все необходимые файлы: `docker-compose` и конфигурация Prometheus.

1. Найти внешний ip докера, по которому изнутри контейнера можно подключаться к портам хоста: `ip addr show docker0`. Нужный ip-адрес записать в `targets`конфига для nvidia-triton в файл `prometheus.yml`.
2. Поднять сервисы:
    ```bash
    cd monitoring
    docker compose -f monitoring_compose.yml up -d
    ```
3. Зайти в Grafana (`localhost:3000`), вручную добавить источник данных (Prometheus, адрес `localhost:9090`), и нужные дашборды (удобно импортировать оригинальный дашборд для nvidia-triton с id 16231 [[ссылка](https://grafana.com/grafana/dashboards/16231-triton/)]).
